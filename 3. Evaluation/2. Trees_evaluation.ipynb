{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagutierrezgu/My_Portfolio/blob/main/Clothes%20image%20classification/Evaluation/Trees_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f85f29c0",
      "metadata": {
        "id": "f85f29c0"
      },
      "source": [
        "### Supervised. Tree decision classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f15b238",
      "metadata": {
        "id": "1f15b238"
      },
      "source": [
        "Respecto a los árboles de decisión entrenados, se usaron varias métricas de evaluación implícitamente en la sección de modelamiento, esto al graficar el porcentaje de errores en las predicciones del modelo, el score dado por el método de GridSearch al buscar los mejores hiperparámetros, entre otros análisis. \n",
        "\n",
        "Otras de las métricas más usadas para evaluar este tipo de modelos supervisados son el f1, recall y precision, así que calculándolas para el conjunto de datos original se tiene:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a432299b",
      "metadata": {
        "id": "a432299b",
        "outputId": "b1bad56b-ed0b-4616-ec49-48665c60ec5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Métricas f1_score, micro y presición avg macro: 0.7687, 0.7698 y 0.7712 respectivamente\n",
            "Métricas f1_score, micro y presición avg micro: 0.7652, 0.7652 y 0.7652 respectivamente\n",
            "Métricas f1_score, micro y presición avg weighted: 0.7658, 0.7652 y 0.7698 respectivamente\n"
          ]
        }
      ],
      "source": [
        "tree = DecisionTreeClassifier(max_depth = 9, random_state=333)\n",
        "tree.fit(x_train, y_train)\n",
        "y_pred = tree.predict(x_test)\n",
        "\n",
        "scores = []\n",
        "a = 0\n",
        "for avg_type in ['macro', 'micro', 'weighted']:\n",
        "    scores.append(metrics.f1_score(y_test, y_pred, average = avg_type))\n",
        "    scores.append(metrics.recall_score(y_test, y_pred, average = avg_type))\n",
        "    scores.append(metrics.precision_score(y_test, y_pred, average = avg_type))\n",
        "    print('''Métricas f1_score, micro y presición avg {}: {:.4f}, {:.4f} y {:.4f} \n",
        "    respectivamente'''.format(avg_type, scores[a], scores[a+1], scores[a+2]))\n",
        "    a += 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ee6f64f",
      "metadata": {
        "id": "1ee6f64f"
      },
      "source": [
        "Los cuales muestran que, teniendo en cuenta que el máximo valor posible es 1, el rendimiento del modelo es bastante alto comparado con lo obtenido en los modelos de K-Means, ya que todos los valores obtenidos están entre $0.76$ y $0.78$, y esto último también deja ver que las diferencias entre cada uno de los scores no son altas.\n",
        "\n",
        "Así mismo, los resultados que se obtienen al aplicar estas métricas sobre el conjunto de datos de menor dimensión son los siguientes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9697007b",
      "metadata": {
        "id": "9697007b",
        "outputId": "ded4d71f-d054-4dc3-949b-a3abc5ebe1a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Métricas f1_score, micro y presición avg macro: 0.7130, 0.7138 y 0.7175 respectivamente\n",
            "Métricas f1_score, micro y presición avg micro: 0.7100, 0.7100 y 0.7100 respectivamente\n",
            "Métricas f1_score, micro y presición avg weighted: 0.7101, 0.7100 y 0.7152 respectivamente\n"
          ]
        }
      ],
      "source": [
        "tree = DecisionTreeClassifier(max_depth = 9, random_state=333)\n",
        "tree.fit(x_train_pca, y_train_pca)\n",
        "y_pred_pca = tree.predict(x_test_pca)\n",
        "\n",
        "scores = []\n",
        "a = 0\n",
        "for avg_type in ['macro', 'micro', 'weighted']:\n",
        "    scores.append(metrics.f1_score(y_test_pca, y_pred_pca, average = avg_type))\n",
        "    scores.append(metrics.recall_score(y_test_pca, y_pred_pca, average = avg_type))\n",
        "    scores.append(metrics.precision_score(y_test_pca, y_pred_pca, average = avg_type))\n",
        "    print('''Métricas f1_score, micro y presición avg {}: {:.4f}, {:.4f} y {:.4f} \n",
        "    respectivamente'''.format(avg_type, scores[a], scores[a+1], scores[a+2]))\n",
        "    a += 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dbbf282",
      "metadata": {
        "id": "2dbbf282"
      },
      "source": [
        "Al igual que en el caso del conjunto de imágenes original, los resultados obtenido son mucho mejores que los del modelo de clustering, sin embargo, este conjunto proveniente del PCA obtiene menores scores que los datos originales, caso contrario a lo que ocurría en los modelos de K-Means hechos, donde los datos de PCA obtenían ligeramente mejores resultados que las imágenes sin reducir su dimensionalidad."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}